{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rev_id\n",
      "37675     this is not creative those are the dictionary ...\n",
      "44816     the term standard model is itself less npov th...\n",
      "49851     true or false the situation as of march 2002 w...\n",
      "89320     next maybe you could work on being less condes...\n",
      "93890                    this page will need disambiguation\n",
      "102817    important note for all sysops there is a bug i...\n",
      "103624    i removed the following all names of early pol...\n",
      "111032    if you ever claimed in a judaic studies progra...\n",
      "120283    my apologies im english i watch cricket i know...\n",
      "128532    someone wrote more recognizable perhaps is a t...\n",
      "133562    correct full biographical details will put dow...\n",
      "138117    care should be taken to distinguish when and i...\n",
      "155243    if i may butt in ive spent the last 14 hour fo...\n",
      "177310    on my you will find the apology that i owe you...\n",
      "192579    i fail to see the distinction who better than ...\n",
      "201190                        gets far more tendentious yet\n",
      "208009    as a person who has done some of this activity...\n",
      "249432    its great that weve found a new source of free...\n",
      "252031    no i really havent heard of either one at leas...\n",
      "268558    id like the concepts of microevolution and mac...\n",
      "Name: comment, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# download_file(ANNOTATED_COMMENTS_URL, 'attack_annotated_comments.tsv')\n",
    "comments = pd.read_csv('attack_annotated_comments.tsv', sep = '\\t', index_col = 0, encoding='ISO-8859-1')\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
    "\n",
    "# transform into lowercase\n",
    "comments['comment'] = comments['comment'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "\n",
    "# remove punctuations\n",
    "comments['comment'] = comments['comment'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "# remove emoji, references: https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "comments['comment'] = comments['comment'].apply(lambda x: remove_emoji(x))\n",
    "\n",
    "# remove whitespace\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.strip())\n",
    "print(comments['comment'].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115864, 2080357)\n",
      "[11.96703382 11.96703382 11.96703382 ... 11.96703382 11.96703382\n",
      " 11.96703382]\n"
     ]
    }
   ],
   "source": [
    "# create BoW model and train\n",
    "# create the feature matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('count', CountVectorizer(stop_words='english', analyzer='word', ngram_range=(2, 2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "]).fit(comments['comment'])\n",
    "\n",
    "\n",
    "vector = pipe['count'].transform(comments['comment'])\n",
    "print(vector.shape)\n",
    "print(pipe['tfidf'].idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
